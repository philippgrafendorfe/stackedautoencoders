{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import TensorBoard\n",
    "from __future__ import print_function\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single layer autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data is normalized and serialized into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_val = x_val.astype('float32') / 255.\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_val = x_val.reshape((len(x_val), np.prod(x_val.shape[1:])))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_val = keras.utils.to_categorical(y_val, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using keras module with compression to 32 floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######## constants for autoencoder ############\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 36\n",
    "input_dim = 784\n",
    "epochs = 50\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input placeholder\n",
    "input_img = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "single_autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "single_encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = single_autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "single_decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll configure our model to use a per-pixel binary crossentropy loss, and the Adadelta optimizer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Cross Entropy = Binomial Cross Entropy = Special Case of Multinomial Cross Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 36)                28260     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 784)               29008     \n",
      "=================================================================\n",
      "Total params: 57,268\n",
      "Trainable params: 57,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "single_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train or load single autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.3693 - val_loss: 0.2727\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2652 - val_loss: 0.2545\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2441 - val_loss: 0.2317\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2231 - val_loss: 0.2130\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2077 - val_loss: 0.2005\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1970 - val_loss: 0.1912\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1889 - val_loss: 0.1841\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1823 - val_loss: 0.1779\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1765 - val_loss: 0.1725\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1713 - val_loss: 0.1674\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1663 - val_loss: 0.1627\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1618 - val_loss: 0.1582\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1575 - val_loss: 0.1541\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1536 - val_loss: 0.1503\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1499 - val_loss: 0.1468\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1465 - val_loss: 0.1437\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1434 - val_loss: 0.1405\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1405 - val_loss: 0.1378\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1378 - val_loss: 0.1351\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1354 - val_loss: 0.1328\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1331 - val_loss: 0.1305\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1309 - val_loss: 0.1284\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1288 - val_loss: 0.1264\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1269 - val_loss: 0.1245\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1250 - val_loss: 0.1227\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1233 - val_loss: 0.1209\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1216 - val_loss: 0.1193\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1200 - val_loss: 0.1177\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1185 - val_loss: 0.1162\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1170 - val_loss: 0.1148\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1157 - val_loss: 0.1134\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1144 - val_loss: 0.1122\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1131 - val_loss: 0.1110\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1120 - val_loss: 0.1099\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1109 - val_loss: 0.1088\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1098 - val_loss: 0.1078\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1089 - val_loss: 0.1068\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1079 - val_loss: 0.1059\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1071 - val_loss: 0.1051\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1063 - val_loss: 0.1043\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1055 - val_loss: 0.1036\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1048 - val_loss: 0.1029\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1041 - val_loss: 0.1023\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1035 - val_loss: 0.1017\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1029 - val_loss: 0.1011\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1024 - val_loss: 0.1006\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1018 - val_loss: 0.1001\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1013 - val_loss: 0.0996\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1009 - val_loss: 0.0991\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1004 - val_loss: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c287dca080>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single_autoencoder = keras.models.load_model('models/single_autoencoder.h5')\n",
    "single_autoencoder.fit(x_train, x_train, \n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True,\n",
    "#                        validation_split = 0.2,\n",
    "                       validation_data=(x_val, x_val),\n",
    "                       callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# single_autoencoder.save('models/single_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0986893922091\n"
     ]
    }
   ],
   "source": [
    "score = single_autoencoder.evaluate(x_val, x_val, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_model(single_autoencoder, to_file='images/single_autoencoder.png', show_shapes=True, show_layer_names=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![single_autoencoder](images/single_autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 50 epochs, the autoencoder seems to reach a stable train/test loss value of about {{score}}. We can try to visualize the reconstructed inputs and the encoded representations. We will use Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoded_imgs = single_encoder.predict(x_val)\n",
    "# decoded_imgs = single_decoder.predict(encoded_imgs)\n",
    "decoded_imgs = single_autoencoder.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_encoder.predict(x_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAAElCAYAAABjz34HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBP4fIhzKfDxcB9cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c284d609e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_val[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code only works if the encoder is compiled during this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACM0AAADSCAYAAABT/6ViAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAMr5L4z/kGSbInn5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c2872b8358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# n = 10\n",
    "# plt.figure(figsize=(40, 10))\n",
    "# for i in range(n):  \n",
    "#     # display encoded\n",
    "#     ax = plt.subplot(2, n, i + 1)\n",
    "#     plt.imshow(encoded_imgs[i].reshape(6, 6))\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(36,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4353 - acc: 0.2539 - val_loss: 1.5491 - val_acc: 0.4761\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.3742 - acc: 0.5125 - val_loss: 0.8687 - val_acc: 0.7279\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.0070 - acc: 0.6500 - val_loss: 0.6456 - val_acc: 0.8145\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.8498 - acc: 0.7073 - val_loss: 0.5454 - val_acc: 0.8359\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.7789 - acc: 0.7301 - val_loss: 0.4967 - val_acc: 0.8489\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.7306 - acc: 0.7497 - val_loss: 0.4572 - val_acc: 0.8648\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.6930 - acc: 0.7634 - val_loss: 0.4322 - val_acc: 0.8690\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.6646 - acc: 0.7756 - val_loss: 0.4171 - val_acc: 0.8737\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6424 - acc: 0.7834 - val_loss: 0.3928 - val_acc: 0.8847\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.6245 - acc: 0.7898 - val_loss: 0.3810 - val_acc: 0.8905\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.6098 - acc: 0.7959 - val_loss: 0.3773 - val_acc: 0.8886\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.6081 - acc: 0.7951 - val_loss: 0.3670 - val_acc: 0.8933\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5963 - acc: 0.7997 - val_loss: 0.3752 - val_acc: 0.8914\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5905 - acc: 0.8017 - val_loss: 0.3524 - val_acc: 0.8969\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.5804 - acc: 0.8065 - val_loss: 0.3507 - val_acc: 0.8972\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5781 - acc: 0.8057 - val_loss: 0.3525 - val_acc: 0.8973\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.5777 - acc: 0.8049 - val_loss: 0.3497 - val_acc: 0.8947\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5719 - acc: 0.8073 - val_loss: 0.3451 - val_acc: 0.8937\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.5626 - acc: 0.8119 - val_loss: 0.3383 - val_acc: 0.8976\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.5646 - acc: 0.8108 - val_loss: 0.3466 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5598 - acc: 0.8130 - val_loss: 0.3358 - val_acc: 0.9012\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5548 - acc: 0.8151 - val_loss: 0.3398 - val_acc: 0.8987\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.5542 - acc: 0.8147 - val_loss: 0.3309 - val_acc: 0.9012\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5467 - acc: 0.8163 - val_loss: 0.3313 - val_acc: 0.9011\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.5426 - acc: 0.8182 - val_loss: 0.3318 - val_acc: 0.8996\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5407 - acc: 0.8189 - val_loss: 0.3300 - val_acc: 0.9020\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5426 - acc: 0.8172 - val_loss: 0.3361 - val_acc: 0.8990\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5367 - acc: 0.8207 - val_loss: 0.3243 - val_acc: 0.9048\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5365 - acc: 0.8208 - val_loss: 0.3261 - val_acc: 0.9031\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5324 - acc: 0.8216 - val_loss: 0.3239 - val_acc: 0.9025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c28c3d8978>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(single_encoder.predict(x_train), y_train, \n",
    "          batch_size=256,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(single_encoder.predict(x_val), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.361680955088\n",
      "Test accuracy: 0.8983\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(single_encoder.predict(x_val), y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######## constants for stacked autoencoder ############\n",
    "input_dim = 784\n",
    "encoding_dim1 = 128\n",
    "encoding_dim2 = 64\n",
    "encoding_dim3 = 32\n",
    "decoding_dim1 = 64\n",
    "decoding_dim2 = 128\n",
    "decoding_dim3 = input_dim\n",
    "epochs = 100\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_img = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim1, activation='relu')(input_img)\n",
    "encoded = Dense(encoding_dim2, activation='relu')(encoded)\n",
    "encoded = Dense(encoding_dim3, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(decoding_dim1, activation='relu')(encoded)\n",
    "decoded = Dense(decoding_dim2, activation='relu')(decoded)\n",
    "decoded = Dense(decoding_dim3, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stacked_autoencoder = Model(input_img, decoded)\n",
    "stacked_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "stacked_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked_autoencoder = keras.models.load_model('models/stacked_autoencoder.h5')\n",
    "# stacked_autoencoder.fit(x_train, x_train,\n",
    "#                 epochs=epochs,\n",
    "#                 batch_size=batch_size,\n",
    "#                 shuffle=True,\n",
    "#                 validation_data=(x_val, x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# stacked_autoencoder.save('models/stacked_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score = stacked_autoencoder.evaluate(x_val, x_val, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(stacked_autoencoder, to_file='images/stacked_autoencoder.png', show_shapes=True, show_layer_names=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stacked_autoencoder](images/stacked_autoencoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decoded_imgs = stacked_autoencoder.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_val[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_val_noisy = x_val + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_val.shape) \n",
    "\n",
    "# re-normalization by clipping to the intervall (0,1)\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_val_noisy = np.clip(x_val_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(x_val_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stick with the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "denoising_autoencoder = Model(input_img, decoded)\n",
    "denoising_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "denoising_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train or load a stacked denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# denoising_autoencoder = keras.models.load_model('models/denoising_autoencoder.h5')\n",
    "denoising_autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val_noisy, x_val),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# denoising_autoencoder.save('models/denoising_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs = denoising_autoencoder.predict(x_val_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_val[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Net to recognize MNIST digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "hidden1_dim = 512\n",
    "hidden2_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(hidden1_dim, activation='relu', input_shape=(input_dim,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(hidden2_dim, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train or load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/model.h5')\n",
    "# model.fit(x_train, y_train, \n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='images/mnist_nn.png', show_shapes=True, show_layer_names=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST Neural Net](images/mnist_nn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_val_noisy, y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of denoised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(decoded_imgs, y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Information and Footage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cross Entropy](images\\2017-12-03 10_42_19-Machine Learning_ Should I use a categorical cross entropy or binary cross entro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size defines number of samples that going to be propagated through the network.\n",
    "\n",
    "For instance, let's say you have 1050 training samples and you want to set up batch_size equal to 100. Algorithm takes first 100 samples (from 1st to 100th) from the training dataset and trains network. Next it takes second 100 samples (from 101st to 200th) and train network again. We can keep doing this procedure until we will propagate through the networks all samples. The problem usually happens with the last set of samples. In our example we've used 1050 which is not divisible by 100 without remainder. The simplest solution is just to get final 50 samples and train the network.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "* It requires less memory. Since you train network using less number of samples the overall training procedure requires less memory. It's especially important in case if you are not able to fit dataset in memory.\n",
    "* Typically networks trains faster with mini-batches. That's because we update weights after each propagation. In our example we've propagated 11 batches (10 of them had 100 samples and 1 had 50 samples) and after each of them we've updated network's parameters. If we used all samples during propagation we would make only 1 update for the network's parameter.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "* The smaller the batch the less accurate estimate of the gradient. In the figure below you can see that mini-batch (green color) gradient's direction fluctuates compare to the full batch (blue color)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network](images\\lU3sx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to be done:\n",
    "- check various encoders with different numbers of hidden layers\n",
    "- feature extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
